\section{Implementation}

For a clear understand, We illustrate some important details of $NO^2$'s implementation in this section. The technologies we used in development and some implementation tricks hidden behind are introduced in brief.

We developed $NO^2$'s instrument tool with a static instrumentation fashion based on DynInst \cite{Dyninst-Deconstruction} library. DynInst library is an Application Program Interface (API) \cite{dyninstapi} that permits the insertion of code into a static binary code or running program. The goal of this API is to provide a machine independent interface to permit the creation of instrumentation tools and applications. And $NO^2$'s implementation of function hits statistics is based on an example of DynInst tools, called CodeCoverage.

Generally, there are three code snippets for the instrument points selector: the initial one for creating some data structures for statistics, the final one for writing back the function hits data to a file, and the common used one for record a function call. For the instrumenter, the initial one for opening a file, the final one for closing a file, and the common used one just for increasing one to the number of tracepoints then writing it to the file. All the code snippets are carefully assembled with DynIsnt API and manipulated with the original binary.

For the purpose of excellent performance, the instrumenter completes the assembly of file operations using the low level system call \emph{open}, \emph{write}, and \emph{close} in Linux Opreating System. The file for saving traces is created in the directory which is mounted as a RAM file system. The RAM file system use memory as a disk in the Virtual File System (VFS) level supported by the Linux Operation System. It means that commonly several memory operations overhead is introduced into the instrumentation of each function hit.

We provide a tasks speculation implementation with ProActive Scheduler \cite{pascheduling}. The ProActive Scheduler can be interacted with a control script. The control script is interpreted in javascript language based on a script engine, called 'Rhino', built-in integrated with the distribution of Java Standard Edition 6(Java SE6). ProActive Scheduler provides the ability of interactive with the scheduler instance at runtime by the fact that script engine can access and invoke the objects and methods in Java.

Our task scheduling policy generator calls the outliers clustering module to establish outliers clustering with updated trace data. Then maintaining a blacklist of nodes, each node in the blacklist has a penalty value. The penalty could be eliminated if no further outliers on a node, and it could be removed from the blacklist. In summary, the blacklist is used for keeping the speculative tasks away from the most possible nodes that may produce outlier tasks. For outliers, the policy generater generate an urgency job description that has a higher priority in the ProActive Scheduler. This urgency job has only one speculative task. Then all this type of urgency jobs containing a speculative task are submitted to the ProActive Scheduler in a speculation priority order. The constraint that no speculation takes place on irregular nodes, can be achieved with a selection script and a claim of nodes selection in the job description. The default speculation interval is three seconds, means that the interactive with the job scheduler is moderate. And each update of trace information has a little communication traffic, only an integer indicated the number of  tracepoints transmitted. This lightweight implementation is acceptable to the job scheduler and the impact of performance can be ignore roughly.

We provide three extra shell scripts for splitting, wrapping native program and merging the results if needed. The shell scripts will be submitted and executed as normal tasks on job scheduler. They can be used immediately in ProActive Scheduler. But it doesn't mean something dependence, Itâ€™s easily to adapt to another scheduler with tiny modification. Taking a picture rendering job for example, there may be three phases for this job: 1. splitting the image into small pieces, 2. rendering them in parallel, 3. merging the rendered parts. These three phases exactly match $NO^2$'s three shell script template : split script, operation script and merge script. Users just need to add an image cutting command into the split script, which may be optional for other jobs. The default procedure copy input files to the destinations can also be modified if needed. In the operation script, the native program must be expressed as a command, a daemon process for traces transferring is also launched as default. When all parts of result has been collected, a merge image command added in the merge script, optional for other jobs too. As described above,  users have an extreme flexibility to make their native programs massive parallel. On the other hand it means $NO^2$ do not provided any file transfer or data placement service and so on, which have been provided by job schedulers or a distributed file system of cluster itself.
